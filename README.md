# **SenticWaveX: Real-time AI-driven Emotion Recognition** üöÄ  

![Windows on Snapdragon](https://img.shields.io/badge/Windows%20on%20Snapdragon-Optimized-blue.svg)  
![ONNXRuntime](https://img.shields.io/badge/ONNXRuntime-Accelerated-purple.svg)  
![Python](https://img.shields.io/badge/Python-3.8%2B-green.svg)  
![License](https://img.shields.io/badge/License-MIT-brightgreen.svg)  

## **üìå Overview**  
**SenticWaveX** is an advanced **real-time AI-driven emotion recognition system** optimized for **Windows on Snapdragon**.  
It processes live audio input, detects emotions using **WavLM**, and applies **ONNX optimization** for ultra-fast inference.  

üîπ **Deep Learning-powered Speech Emotion Analysis**  
üîπ **Optimized with ONNXRuntime for Snapdragon Acceleration**  
üîπ **Confidence Boosting & Emotion Smoothing for Accuracy**  
üîπ **Real-time Audio Processing with Sounddevice**  
üîπ **Multi-threaded Execution for Low Latency**  

---

## **üõ†Ô∏è Technologies Used**  
- **Languages:** Python  
- **Frameworks & Libraries:** PyTorch, Transformers (Hugging Face), ONNXRuntime, Torchaudio, Sounddevice, NumPy  
- **APIs:** Hugging Face Model Hub (for WavLM), ONNX API, Sounddevice API  
- **Other Technologies:** ONNX, Qualcomm QNN Execution Provider, Multi-threading (Thread, Queue, Event)  

---

## **üéØ Features**  
‚úÖ **Real-time Emotion Detection** ‚Äì Classifies emotions: **Angry, Happy, Sad, Neutral, Surprised, Fearful, Disgusted**  
‚úÖ **ONNX Optimization** ‚Äì Converts WavLM model to ONNX for fast, hardware-accelerated inference  
‚úÖ **Confidence Boosting** ‚Äì Enhances prediction accuracy using **probability transition matrices**  
‚úÖ **Adaptive Noise Handling** ‚Äì Uses **SNR-based filtering** for cleaner speech processing  
‚úÖ **Error Handling & Logging** ‚Äì Custom exception handling with colored logs  

---

### **üîπ Prerequisites**  
Ensure you have the following installed:  
- **Python 3.10.8 or approx**  
- **pip** (Python package manager)  
- **ONNXRuntime** (`onnxruntime` for CPU, `onnxruntime-gpu` for NVIDIA, or `onnxruntime-qnn` for Snapdragon)  

### **üîπ Setup**  
1Ô∏è‚É£ **Clone the repository**  
```bash
git clone https://github.com/your-repo/SenticWaveX.git
cd SenticWaveX

2Ô∏è‚É£ Create a virtual environment (optional but recommended)

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
3Ô∏è‚É£ Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
4Ô∏è‚É£ Download WavLM Model (Caches automatically)

bash
Copy
Edit
python -c "from transformers import WavLMForSequenceClassification; WavLMForSequenceClassification.from_pretrained('microsoft/wavlm-base-plus')"
üöÄ Usage
üîπ Running Real-time Emotion Detection
bash
Copy
Edit
python emmo2.py --verbose --confidence-threshold 0.6
üîπ Available Arguments
Argument	Description	Default
--duration	Duration to run the analysis (0 for unlimited)	0
--verbose	Enable detailed logs	False
--device	Specify an audio input device index	Default
--confidence-threshold	Confidence threshold for emotion detection (0.0-1.0)	0.6
--history-size	Number of past predictions to smooth results	5
Example:

bash
Copy
Edit
python emmo2.py --duration 10 --verbose --confidence-threshold 0.7
üñ•Ô∏è How It Works
1Ô∏è‚É£ Audio Processing & Feature Extraction
Captures real-time audio from input devices using Sounddevice API
Applies preprocessing & normalization
Uses Wav2Vec2FeatureExtractor for speech feature extraction
2Ô∏è‚É£ Deep Learning-based Emotion Recognition
WavLM (Hugging Face) processes audio signals
Model predicts 7 emotion classes with softmax probabilities
3Ô∏è‚É£ ONNX Optimization & Hardware Acceleration
Converts PyTorch model to ONNX
Executes inference using ONNXRuntime
Uses QNN Execution Provider (Qualcomm) or CPU fallback
4Ô∏è‚É£ Confidence Boosting & Emotion Smoothing
Applies probability transition matrix to stabilize predictions
Uses signal-to-noise ratio (SNR) filtering for quality enhancement
Maintains prediction history (past 5 results) for consistent outputs
üìå Example Output
bash
Copy
Edit
[16:45:12] Emotion: Happy     Confidence: 92.5%  Time remaining: 9.5s
[16:45:13] Emotion: Happy     Confidence: 91.8%  Time remaining: 8.5s
[16:45:14] Emotion: Neutral   Confidence: 78.2%  Time remaining: 7.5s
[16:45:15] Emotion: Neutral   Confidence: 79.5%  Time remaining: 6.5s
üõ†Ô∏è Troubleshooting
üîπ Issue: No audio device detected

Try specifying a different device:
bash
Copy
Edit
python emmo2.py --device 1
Check available devices:
python
Copy
Edit
import sounddevice as sd
print(sd.query_devices())
üîπ Issue: ONNX model conversion fails

Ensure ONNXRuntime is installed:
bash
Copy
Edit
pip install onnxruntime
Try manually converting the model:
python
Copy
Edit
python -c "import torch; from transformers import WavLMForSequenceClassification; model = WavLMForSequenceClassification.from_pretrained('microsoft/wavlm-base-plus'); torch.onnx.export(model, torch.randn(1, 8000), 'wavlm_optimized.onnx')"
üìú License
This project is licensed under the MIT License. See the LICENSE file for details.

